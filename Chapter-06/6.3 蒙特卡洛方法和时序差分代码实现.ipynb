{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9cebd4",
   "metadata": {},
   "source": [
    "## 初始化环境\n",
    "www.gymlibrary.dev/environments/toy_text/blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2e6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    " \n",
    "env = gym.make(\"Blackjack-v1\")  #加载21点游戏环境Blackjack-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60752f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Discrete(32), Discrete(11), Discrete(2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看观测空间\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8b4638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看行为空间\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bab38",
   "metadata": {},
   "source": [
    "## 21点游戏过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d21061d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 胜利\n",
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21475918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 4, False), 0.0, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(1) #要牌\n",
    "next_state, reward, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3315607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 4, False), -1.0, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(0) #不要牌\n",
    "next_state, reward, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090338bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 胜利\n",
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586ab71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 2, True), 1.0, True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(0) #不要牌\n",
    "next_state, reward, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca534178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 失败\n",
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3587068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, False), -1.0, True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(0) #不要牌\n",
    "next_state, reward, terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1321a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10, False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 失败\n",
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53f7e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 10, False), -1.0, True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, terminated, truncated, info = env.step(1) #要牌\n",
    "next_state, reward, terminated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7b8b3",
   "metadata": {},
   "source": [
    "## 蒙特卡洛方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8c4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化Q值表，用于存储Q(state,action)\n",
    "Q = {}\n",
    "explore_rate = 0.2 # 探索率为0.2\n",
    "policy = {} # 创建空字典作为策略表，存储在状态s下选择动作a的概率\n",
    "rewards = {} # 创建空字典用于保存(state,action)对的累积奖励\n",
    "num_episodes = 5000 # 总回合数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23381c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟回合\n",
    "def generate_episode(Q,policy):\n",
    "    #回合观测序列列表\n",
    "    episode = []\n",
    "    # 初始化环境并获取初始状态\n",
    "    state, _ = env.reset()\n",
    "    while True:\n",
    "        # 若状态s第一次出现，将它添加到Q和policy中\n",
    "        if state not in Q.keys():\n",
    "            Q[state] = {0:0, 1:0} #初始化stick和hit的Q值\n",
    "            policy[state] = [0.5, 0.5] #初始化stick和hit的概率，各为0.5\n",
    "            rewards[state] = {0:[] , 1: []} #初始化空列表用于存储累积奖励\n",
    "        # 利用policy采样一个动作\n",
    "        action = np.random.choice([0,1], p=policy[state],size=1)[0]\n",
    "        #与环境交互，产生奖励与下一状态\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        #将状态state、动作action、奖励reward添加到episode中\n",
    "        episode.append((state, action, reward))\n",
    "        #到达终止状态，循环结束\n",
    "        if terminated:\n",
    "            break\n",
    "        state = next_state\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af54eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始学习\n",
    "for i in range(num_episodes):\n",
    "    #产生一个观测序列，包括该回合每一步的state,action, reward\n",
    "    episode = generate_episode(Q, policy)\n",
    "    #初始化该回合累积奖励\n",
    "    episode_sum_reward = 0.0\n",
    "    #反向遍历观测序列中的每一步\n",
    "    for t in range(len(episode))[::-1]:\n",
    "        #分别保存每一步的状态、动作和奖励\n",
    "        state ,action, reward = episode[t]\n",
    "        #计算累积奖励\n",
    "        episode_sum_reward += reward\n",
    "        #将episode_sum_reward加入（state，action）的rewards中\n",
    "        rewards[state][action].append(episode_sum_reward)\n",
    "        # 更新Q表中的Q值\n",
    "        Q[state][action] = np.mean(rewards[state][action])\n",
    "        # 更新策略\n",
    "        policy_action = np.argmax(list(Q[state].values()))\n",
    "        policy[state][policy_action] = 1 - explore_rate\n",
    "        policy[state][1 - policy_action] = explore_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ab877",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe06fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a446d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1318.0\n"
     ]
    }
   ],
   "source": [
    "# 总奖励\n",
    "total_rewards = 0\n",
    "for k,v in rewards.items():\n",
    "    total_rewards += sum(v[0])\n",
    "    total_rewards += sum(v[1])\n",
    "print(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e308dbfb",
   "metadata": {},
   "source": [
    "## 时序差分方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56b9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化Q值表，用于存储Q(state,action)\n",
    "Q = {}\n",
    "explore_rate = 0.2 # 探索率为0.2\n",
    "policy = {} # 创建空字典作为策略表，存储在状态s下选择动作a的概率\n",
    "rewards = {} # 创建空字典用于保存(state,action)对的累积奖励\n",
    "num_episodes = 5000 # 总回合数\n",
    "alpha = 0.1  # 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6554e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成回合\n",
    "def generate_episode(Q,policy):\n",
    "    #回合观测序列列表\n",
    "    episode = []\n",
    "    # 初始化环境并获取初始状态\n",
    "    state, _ = env.reset()\n",
    "    while True:\n",
    "        # 若状态s第一次出现，将它添加到Q和policy中\n",
    "        if state not in Q.keys():\n",
    "            Q[state] = {0:0, 1:0} #初始化stick和hit的Q值\n",
    "            policy[state] = [0.5, 0.5] #初始化stick和hit的概率，各为0.5\n",
    "            rewards[state] = {0:[] , 1: []} #初始化空列表用于存储累积奖励\n",
    "        # 利用policy采样一个动作\n",
    "        action = np.random.choice([0,1], p=policy[state],size=1)[0]\n",
    "        #与环境交互，产生奖励与下一状态\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        #将状态state、动作action、奖励reward添加到episode中\n",
    "        episode.append((state, action, reward, next_state))\n",
    "        #到达终止状态，循环结束\n",
    "        if terminated:\n",
    "            break\n",
    "        state = next_state\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad2e0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始学习\n",
    "for i in range(num_episodes):\n",
    "    #产生一个观测序列，包括该回合每一步的state,action, reward\n",
    "    episode = generate_episode(Q, policy)\n",
    "    #初始化该回合累积奖励\n",
    "    episode_sum_reward = 0.0\n",
    "    #反向遍历观测序列中的每一步\n",
    "    for t in range(len(episode)):\n",
    "        #分别保存每一步的状态、动作和奖励\n",
    "        state ,action, reward, next_state = episode[t]\n",
    "        if next_state not in Q.keys():\n",
    "            Q[next_state] = {0: 0.0, 1: 0.0}\n",
    "        #计算累积奖励\n",
    "        episode_sum_reward += reward\n",
    "        #将episode_sum_reward加入（state，action）的rewards中\n",
    "        rewards[state][action].append(episode_sum_reward)\n",
    "        # TD（0）方式更新Q表中的Q值\n",
    "        Q[state][action] += alpha * (reward + max(Q[next_state].values()) - Q[state][action])\n",
    "        # 更新策略\n",
    "        policy_action = np.argmax(list(Q[state].values()))\n",
    "        policy[state][policy_action] = 1 - explore_rate\n",
    "        policy[state][1 - policy_action] = explore_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f3285a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(20, 10, False): [0.8, 0.2],\n",
       " (12, 10, False): [0.2, 0.8],\n",
       " (15, 8, False): [0.2, 0.8],\n",
       " (19, 8, False): [0.8, 0.2],\n",
       " (20, 6, False): [0.8, 0.2],\n",
       " (21, 6, False): [0.8, 0.2],\n",
       " (12, 6, True): [0.8, 0.2],\n",
       " (16, 6, True): [0.2, 0.8],\n",
       " (20, 6, True): [0.8, 0.2],\n",
       " (21, 6, True): [0.8, 0.2],\n",
       " (7, 10, False): [0.2, 0.8],\n",
       " (14, 6, False): [0.2, 0.8],\n",
       " (7, 5, False): [0.8, 0.2],\n",
       " (11, 5, False): [0.2, 0.8],\n",
       " (21, 5, False): [0.8, 0.2],\n",
       " (13, 2, False): [0.2, 0.8],\n",
       " (10, 5, False): [0.2, 0.8],\n",
       " (15, 2, False): [0.2, 0.8],\n",
       " (16, 2, False): [0.2, 0.8],\n",
       " (17, 10, False): [0.2, 0.8],\n",
       " (13, 3, True): [0.2, 0.8],\n",
       " (20, 3, True): [0.8, 0.2],\n",
       " (17, 7, True): [0.2, 0.8],\n",
       " (6, 3, False): [0.2, 0.8],\n",
       " (18, 10, False): [0.2, 0.8],\n",
       " (18, 3, False): [0.8, 0.2],\n",
       " (9, 3, False): [0.8, 0.2],\n",
       " (9, 5, False): [0.2, 0.8],\n",
       " (19, 5, False): [0.8, 0.2],\n",
       " (12, 4, True): [0.2, 0.8],\n",
       " (14, 4, True): [0.2, 0.8],\n",
       " (19, 10, False): [0.2, 0.8],\n",
       " (7, 1, False): [0.2, 0.8],\n",
       " (17, 4, False): [0.8, 0.2],\n",
       " (8, 10, False): [0.2, 0.8],\n",
       " (4, 10, False): [0.2, 0.8],\n",
       " (15, 3, False): [0.8, 0.2],\n",
       " (19, 1, False): [0.2, 0.8],\n",
       " (18, 8, False): [0.8, 0.2],\n",
       " (21, 10, False): [0.8, 0.2],\n",
       " (17, 8, True): [0.2, 0.8],\n",
       " (17, 8, False): [0.2, 0.8],\n",
       " (7, 3, False): [0.2, 0.8],\n",
       " (20, 9, False): [0.8, 0.2],\n",
       " (12, 2, False): [0.2, 0.8],\n",
       " (10, 1, False): [0.2, 0.8],\n",
       " (20, 1, False): [0.8, 0.2],\n",
       " (14, 4, False): [0.2, 0.8],\n",
       " (14, 10, False): [0.2, 0.8],\n",
       " (19, 3, False): [0.8, 0.2],\n",
       " (9, 7, False): [0.2, 0.8],\n",
       " (17, 7, False): [0.2, 0.8],\n",
       " (21, 7, False): [0.8, 0.2],\n",
       " (10, 10, False): [0.2, 0.8],\n",
       " (17, 2, False): [0.8, 0.2],\n",
       " (13, 10, False): [0.2, 0.8],\n",
       " (15, 10, False): [0.2, 0.8],\n",
       " (21, 1, True): [0.8, 0.2],\n",
       " (9, 10, False): [0.2, 0.8],\n",
       " (12, 1, False): [0.2, 0.8],\n",
       " (16, 10, True): [0.2, 0.8],\n",
       " (19, 7, False): [0.8, 0.2],\n",
       " (20, 2, False): [0.8, 0.2],\n",
       " (21, 3, True): [0.8, 0.2],\n",
       " (12, 6, False): [0.2, 0.8],\n",
       " (12, 5, False): [0.8, 0.2],\n",
       " (13, 5, False): [0.2, 0.8],\n",
       " (14, 5, False): [0.2, 0.8],\n",
       " (15, 4, False): [0.2, 0.8],\n",
       " (11, 1, False): [0.2, 0.8],\n",
       " (20, 4, False): [0.8, 0.2],\n",
       " (13, 4, False): [0.2, 0.8],\n",
       " (9, 1, False): [0.8, 0.2],\n",
       " (19, 9, False): [0.8, 0.2],\n",
       " (14, 1, False): [0.2, 0.8],\n",
       " (13, 9, False): [0.2, 0.8],\n",
       " (13, 6, False): [0.2, 0.8],\n",
       " (16, 9, False): [0.2, 0.8],\n",
       " (8, 7, False): [0.2, 0.8],\n",
       " (21, 2, True): [0.8, 0.2],\n",
       " (12, 8, False): [0.2, 0.8],\n",
       " (16, 10, False): [0.2, 0.8],\n",
       " (17, 1, False): [0.2, 0.8],\n",
       " (18, 1, False): [0.2, 0.8],\n",
       " (14, 2, False): [0.2, 0.8],\n",
       " (14, 2, True): [0.2, 0.8],\n",
       " (17, 2, True): [0.2, 0.8],\n",
       " (21, 2, False): [0.8, 0.2],\n",
       " (11, 6, False): [0.2, 0.8],\n",
       " (8, 6, False): [0.2, 0.8],\n",
       " (14, 3, False): [0.2, 0.8],\n",
       " (20, 8, False): [0.8, 0.2],\n",
       " (15, 5, False): [0.2, 0.8],\n",
       " (18, 5, False): [0.8, 0.2],\n",
       " (21, 7, True): [0.8, 0.2],\n",
       " (16, 7, False): [0.2, 0.8],\n",
       " (20, 7, False): [0.8, 0.2],\n",
       " (5, 5, False): [0.2, 0.8],\n",
       " (20, 1, True): [0.8, 0.2],\n",
       " (19, 2, False): [0.8, 0.2],\n",
       " (21, 8, True): [0.2, 0.8],\n",
       " (7, 7, False): [0.2, 0.8],\n",
       " (15, 7, False): [0.2, 0.8],\n",
       " (21, 4, True): [0.8, 0.2],\n",
       " (13, 3, False): [0.2, 0.8],\n",
       " (13, 8, False): [0.2, 0.8],\n",
       " (12, 4, False): [0.2, 0.8],\n",
       " (8, 3, False): [0.2, 0.8],\n",
       " (19, 3, True): [0.8, 0.2],\n",
       " (14, 8, False): [0.2, 0.8],\n",
       " (6, 2, False): [0.2, 0.8],\n",
       " (16, 3, False): [0.2, 0.8],\n",
       " (5, 1, False): [0.2, 0.8],\n",
       " (7, 4, False): [0.2, 0.8],\n",
       " (16, 4, False): [0.8, 0.2],\n",
       " (18, 10, True): [0.2, 0.8],\n",
       " (17, 1, True): [0.2, 0.8],\n",
       " (19, 1, True): [0.2, 0.8],\n",
       " (8, 5, False): [0.2, 0.8],\n",
       " (16, 6, False): [0.2, 0.8],\n",
       " (15, 10, True): [0.2, 0.8],\n",
       " (17, 10, True): [0.2, 0.8],\n",
       " (5, 2, False): [0.8, 0.2],\n",
       " (18, 9, False): [0.8, 0.2],\n",
       " (19, 10, True): [0.2, 0.8],\n",
       " (8, 1, False): [0.2, 0.8],\n",
       " (16, 1, False): [0.2, 0.8],\n",
       " (6, 8, False): [0.2, 0.8],\n",
       " (11, 10, False): [0.2, 0.8],\n",
       " (16, 5, False): [0.8, 0.2],\n",
       " (10, 6, False): [0.2, 0.8],\n",
       " (19, 4, False): [0.8, 0.2],\n",
       " (10, 2, False): [0.2, 0.8],\n",
       " (20, 2, True): [0.8, 0.2],\n",
       " (11, 3, False): [0.2, 0.8],\n",
       " (13, 10, True): [0.2, 0.8],\n",
       " (6, 7, False): [0.2, 0.8],\n",
       " (10, 4, False): [0.2, 0.8],\n",
       " (15, 6, False): [0.2, 0.8],\n",
       " (17, 3, False): [0.2, 0.8],\n",
       " (9, 8, False): [0.2, 0.8],\n",
       " (9, 4, False): [0.2, 0.8],\n",
       " (6, 1, False): [0.8, 0.2],\n",
       " (10, 8, False): [0.2, 0.8],\n",
       " (9, 9, False): [0.2, 0.8],\n",
       " (11, 4, False): [0.2, 0.8],\n",
       " (21, 4, False): [0.8, 0.2],\n",
       " (21, 10, True): [0.8, 0.2],\n",
       " (11, 2, False): [0.2, 0.8],\n",
       " (18, 2, False): [0.8, 0.2],\n",
       " (17, 6, False): [0.8, 0.2],\n",
       " (18, 4, False): [0.8, 0.2],\n",
       " (19, 6, False): [0.8, 0.2],\n",
       " (14, 7, False): [0.2, 0.8],\n",
       " (13, 1, False): [0.2, 0.8],\n",
       " (17, 9, False): [0.2, 0.8],\n",
       " (15, 1, False): [0.2, 0.8],\n",
       " (12, 3, False): [0.2, 0.8],\n",
       " (10, 3, False): [0.2, 0.8],\n",
       " (20, 3, False): [0.8, 0.2],\n",
       " (18, 7, False): [0.8, 0.2],\n",
       " (14, 7, True): [0.8, 0.2],\n",
       " (5, 10, False): [0.2, 0.8],\n",
       " (14, 1, True): [0.2, 0.8],\n",
       " (19, 5, True): [0.8, 0.2],\n",
       " (8, 9, False): [0.2, 0.8],\n",
       " (19, 9, True): [0.2, 0.8],\n",
       " (14, 9, False): [0.2, 0.8],\n",
       " (15, 9, False): [0.2, 0.8],\n",
       " (6, 10, False): [0.2, 0.8],\n",
       " (17, 5, False): [0.8, 0.2],\n",
       " (20, 10, True): [0.2, 0.8],\n",
       " (10, 9, False): [0.2, 0.8],\n",
       " (18, 6, False): [0.8, 0.2],\n",
       " (21, 1, False): [0.8, 0.2],\n",
       " (15, 7, True): [0.2, 0.8],\n",
       " (13, 7, False): [0.2, 0.8],\n",
       " (4, 2, False): [0.2, 0.8],\n",
       " (9, 2, False): [0.2, 0.8],\n",
       " (6, 4, False): [0.8, 0.2],\n",
       " (19, 6, True): [0.2, 0.8],\n",
       " (20, 4, True): [0.8, 0.2],\n",
       " (12, 7, True): [0.2, 0.8],\n",
       " (4, 5, False): [0.8, 0.2],\n",
       " (12, 9, False): [0.2, 0.8],\n",
       " (21, 8, False): [0.8, 0.2],\n",
       " (16, 1, True): [0.2, 0.8],\n",
       " (11, 9, False): [0.2, 0.8],\n",
       " (18, 1, True): [0.2, 0.8],\n",
       " (12, 7, False): [0.2, 0.8],\n",
       " (15, 2, True): [0.2, 0.8],\n",
       " (8, 4, False): [0.8, 0.2],\n",
       " (16, 8, False): [0.8, 0.2],\n",
       " (4, 8, False): [0.2, 0.8],\n",
       " (18, 5, True): [0.8, 0.2],\n",
       " (5, 6, False): [0.8, 0.2],\n",
       " (11, 8, False): [0.2, 0.8],\n",
       " (7, 8, False): [0.2, 0.8],\n",
       " (20, 5, False): [0.8, 0.2],\n",
       " (18, 9, True): [0.8, 0.2],\n",
       " (15, 3, True): [0.2, 0.8],\n",
       " (17, 6, True): [0.2, 0.8],\n",
       " (4, 6, False): [0.8, 0.2],\n",
       " (17, 4, True): [0.2, 0.8],\n",
       " (4, 3, False): [0.2, 0.8],\n",
       " (13, 1, True): [0.2, 0.8],\n",
       " (19, 4, True): [0.8, 0.2],\n",
       " (4, 9, False): [0.2, 0.8],\n",
       " (12, 10, True): [0.2, 0.8],\n",
       " (11, 7, False): [0.2, 0.8],\n",
       " (4, 1, False): [0.2, 0.8],\n",
       " (7, 2, False): [0.2, 0.8],\n",
       " (15, 1, True): [0.2, 0.8],\n",
       " (21, 5, True): [0.8, 0.2],\n",
       " (6, 6, False): [0.2, 0.8],\n",
       " (21, 3, False): [0.8, 0.2],\n",
       " (12, 2, True): [0.2, 0.8],\n",
       " (6, 9, False): [0.2, 0.8],\n",
       " (20, 9, True): [0.2, 0.8],\n",
       " (14, 6, True): [0.2, 0.8],\n",
       " (13, 4, True): [0.2, 0.8],\n",
       " (18, 4, True): [0.2, 0.8],\n",
       " (19, 8, True): [0.8, 0.2],\n",
       " (21, 9, True): [0.8, 0.2],\n",
       " (6, 5, False): [0.8, 0.2],\n",
       " (18, 3, True): [0.2, 0.8],\n",
       " (7, 6, False): [0.8, 0.2],\n",
       " (15, 8, True): [0.2, 0.8],\n",
       " (19, 7, True): [0.8, 0.2],\n",
       " (14, 10, True): [0.2, 0.8],\n",
       " (21, 9, False): [0.8, 0.2],\n",
       " (5, 7, False): [0.2, 0.8],\n",
       " (17, 3, True): [0.8, 0.2],\n",
       " (7, 9, False): [0.2, 0.8],\n",
       " (9, 6, False): [0.8, 0.2],\n",
       " (18, 2, True): [0.2, 0.8],\n",
       " (20, 8, True): [0.8, 0.2],\n",
       " (12, 1, True): [0.8, 0.2],\n",
       " (8, 2, False): [0.2, 0.8],\n",
       " (19, 2, True): [0.8, 0.2],\n",
       " (10, 7, False): [0.2, 0.8],\n",
       " (18, 8, True): [0.8, 0.2],\n",
       " (16, 4, True): [0.8, 0.2],\n",
       " (16, 5, True): [0.2, 0.8],\n",
       " (16, 8, True): [0.2, 0.8],\n",
       " (16, 9, True): [0.2, 0.8],\n",
       " (5, 8, False): [0.2, 0.8],\n",
       " (16, 7, True): [0.8, 0.2],\n",
       " (16, 3, True): [0.2, 0.8],\n",
       " (17, 9, True): [0.2, 0.8],\n",
       " (5, 4, False): [0.2, 0.8],\n",
       " (20, 5, True): [0.8, 0.2],\n",
       " (8, 8, False): [0.2, 0.8],\n",
       " (15, 5, True): [0.8, 0.2],\n",
       " (17, 5, True): [0.8, 0.2],\n",
       " (13, 8, True): [0.8, 0.2],\n",
       " (14, 5, True): [0.2, 0.8],\n",
       " (14, 9, True): [0.8, 0.2],\n",
       " (14, 8, True): [0.2, 0.8],\n",
       " (12, 8, True): [0.2, 0.8],\n",
       " (13, 5, True): [0.8, 0.2],\n",
       " (4, 7, False): [0.2, 0.8],\n",
       " (20, 7, True): [0.2, 0.8],\n",
       " (12, 5, True): [0.2, 0.8],\n",
       " (13, 6, True): [0.2, 0.8],\n",
       " (16, 2, True): [0.2, 0.8],\n",
       " (15, 9, True): [0.8, 0.2],\n",
       " (4, 4, False): [0.2, 0.8],\n",
       " (15, 4, True): [0.2, 0.8],\n",
       " (13, 7, True): [0.8, 0.2],\n",
       " (13, 2, True): [0.2, 0.8],\n",
       " (12, 9, True): [0.2, 0.8],\n",
       " (12, 3, True): [0.2, 0.8],\n",
       " (14, 3, True): [0.2, 0.8],\n",
       " (18, 7, True): [0.8, 0.2],\n",
       " (5, 9, False): [0.2, 0.8],\n",
       " (18, 6, True): [0.8, 0.2],\n",
       " (5, 3, False): [0.2, 0.8]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3db78f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1302.0\n"
     ]
    }
   ],
   "source": [
    "# 总奖励\n",
    "total_rewards = 0\n",
    "for k,v in rewards.items():\n",
    "    total_rewards += sum(v[0])\n",
    "    total_rewards += sum(v[1])\n",
    "print(total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
