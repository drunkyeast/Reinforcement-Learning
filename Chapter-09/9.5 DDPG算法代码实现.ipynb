{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73f7b37",
   "metadata": {},
   "source": [
    "### 初始化环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1bc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在jupyter notebook里env.render看不到窗口\n",
    "# 写一个helper类，用matplotlib刷新显示图像\n",
    "# 初始化传入env，调用helper的render即可\n",
    "from IPython import display # 导入display模块，用于在Jupyter Notebook中显示图像\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # 导入matplotlib库，用于绘制图像\n",
    "%matplotlib inline\n",
    "\n",
    "class GymHelper:\n",
    "    def __init__(self, env, figsize = (3, 3)):\n",
    "        self.env = env # 初始化Gym环境\n",
    "        self.figsize = figsize # 初始化绘图窗口大小\n",
    "        \n",
    "        plt.figure(figsize = figsize) # 创建绘图窗口\n",
    "        plt.title(self.env.spec.id) # 标题设为环境名\n",
    "        self.img = plt.imshow(env.render()) # 在绘图窗口中显示初始图像\n",
    "    \n",
    "    def render(self, title = None):\n",
    "        image_data = self.env.render() # 获取当前环境图像渲染数据\n",
    "        \n",
    "        self.img.set_data(image_data) # 更新绘图窗口中的图像数据\n",
    "        display.display(plt.gcf()) # 刷新显示\n",
    "        display.clear_output(wait = True) # 有新图片时再清除绘图窗口原有图像\n",
    "        if title: # 如果有标题，就显示标题\n",
    "            plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728446d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASAAAADdCAYAAAAb+K/zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhtUlEQVR4nO3daVQUVxo38H91N93QQjfI0g0CikpUAnEBwcbXJBMxBD1JXCZmjDMSs6KY0cTJJHxInOS8M2QZzTJRk5OMuCQTJ5rozCguCK5JiyAgrmhUBJUlinSzNtD9vB8I9dqCsggUjc/vnHtiV92uulWh/qfq3qpqgYgIjDEmAZnUDWCM3bs4gBhjkuEAYoxJhgOIMSYZDiDGmGQ4gBhjkuEAYoxJhgOIMSYZDiDGmGQ4gFi7CgsLIQgC1q5d26XvC4KAv/zlL536zsMPP4zQ0NAura+zutI+1j04gBgAYO3atRAEoc3y5ptvSt081k8ppG4A61veffddBAUF2U27//77sXbtWjg5OXVpmXV1dVAo+E+NtcZ/FcxOXFwcIiIiunWZzs7O3bo81n/wJRhrV1t9QM8++yxcXV1x5coVTJ8+Ha6urvD29saf/vQnWK1Wu+/f2sdSVVWFJUuWYMiQIVCpVPDx8cGUKVOQk5PTat2nTp3Cb37zG6jVagwaNAgffPBBqzoWiwXLli3D8OHDoVKpEBAQgD//+c+wWCyt6r366qvw9vaGm5sbnnjiCVy+fPnudg67K3wGxOyYTCZcu3atQ3WtVitiY2MRFRWFv//979izZw+WL1+OYcOGYcGCBbf9XkJCAjZv3oxFixYhJCQE169fx6FDh3D69GmMGzdOrHfjxg089thjmDlzJmbPno3NmzfjjTfeQFhYGOLi4gAANpsNTzzxBA4dOoSXXnoJo0aNwvHjx/HRRx/h7Nmz2Lp1q7i8F154AV9//TWeeeYZREdHIyMjA9OmTevajmLdgxgjopSUFALQZrl48SIBoJSUFLF+fHw8AaB3333Xbjljx46l8PBwu2kAaNmyZeJnrVZLiYmJd2zPQw89RABo/fr14jSLxUJ6vZ5mzZolTtuwYQPJZDI6ePCg3fc///xzAkA//vgjERHl5eURAFq4cKFdvWeeeaZV+1jv4TMgZmflypW47777Olw/ISHB7vOkSZOwYcOGO37H3d0dmZmZuHr1Kvz8/G5bz9XVFb///e/Fz0qlEpGRkbhw4YI4bdOmTRg1ahRGjhxpd+b2yCOPAAD27t2L6OhopKamAgD++Mc/2q1jyZIl+Ne//tXOVrKewgHE7ERGRrbqhC4sLGyzrrOzM7y9ve2meXh44MaNG3dcxwcffID4+HgEBAQgPDwcU6dOxbx58zB06FC7ev7+/hAEodXy8/Pzxc/nzp3D6dOnW7WjRXl5OQDg0qVLkMlkGDZsmN38ESNG3LGtrGdxALEuk8vlXfre7NmzMWnSJGzZsgW7d+/Ghx9+iPfffx8//PCD2Ldzp+XTTW8RttlsCAsLw4oVK9qsGxAQ0KU2st7BAcQk4evri4ULF2LhwoUoLy/HuHHj8Ne//tUugDpi2LBhOHbsGCZPntzqbOlmgwcPhs1mw/nz5+3OegoKCrq8Dezu8TA861VWqxUmk8lumo+PD/z8/FoNm3fE7NmzceXKFXz55Zet5tXV1aGmpgYAxGD79NNP7ep8/PHHnV4n6z58BsR6VVVVFfz9/fHb3/4Wo0ePhqurK/bs2YOsrCwsX76808v7wx/+gO+++w4JCQnYu3cvJk6cCKvVijNnzuC7777Drl27EBERgTFjxmDOnDlYtWoVTCYToqOjkZ6ejp9//rkHtpJ1FAcQ61VqtRoLFy7E7t278cMPP8Bms2H48OFYtWrVHe8duh2ZTIatW7fio48+wvr167Flyxao1WoMHToUixcvthvRW7NmDby9vfHNN99g69ateOSRR7B9+3buJ5KQQMS/C8YYkwb3ATHGJMMBxBiTDAcQY0wykgXQypUrMWTIEDg7OyMqKgpHjhyRqimMMYlIEkD//ve/8dprr2HZsmXIycnB6NGjERsbK942zxi7N0gyChYVFYXx48fjs88+A9B8O31AQABeeeUVfv0nY/eQXr8PqKGhAUePHkVSUpI4TSaTISYmBkajsc3vWCwWu7tkbTYbKioq4Onpecfb7xlj0iAiVFVVwc/PDzLZ7S+0ej2Arl27BqvVCp1OZzddp9PhzJkzbX4nOTkZ77zzTm80jzHWjYqLi+Hv73/b+Q4xCpaUlASTySSWoqIiqZvEGOsANze3O87v9TMgLy8vyOVylJWV2U0vKyuDXq9v8zsqlQoqlao3mscY60btdZH0+hmQUqlEeHg40tPTxWk2mw3p6ekwGAy93RzGmIQkeRj1tddeQ3x8PCIiIhAZGYmPP/4YNTU1mD9/vhTNYYxJRJIAevrpp/HLL7/g7bffRmlpKcaMGYOdO3e26phmjPVvDvk0vNlshlarlboZjLF2mEwmaDSa2853iFEwxlj/xAHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXQ6gA4cOIDHH38cfn5+EAQBW7dutZtPRHj77bfh6+sLFxcXxMTE4Ny5c3Z1KioqMHfuXGg0Gri7u+P5559HdXX1XW0IY8zxdDqAampqMHr0aKxcubLN+R988AE+/fRTfP7558jMzMSAAQMQGxuL+vp6sc7cuXNx8uRJpKWlYdu2bThw4ABeeumlrm8FY8wx0V0AQFu2bBE/22w20uv19OGHH4rTKisrSaVS0bfffktERKdOnSIAlJWVJdbZsWMHCYJAV65c6dB6TSYTAeDChUsfLyaT6Y7Hcrf2AV28eBGlpaWIiYkRp2m1WkRFRcFoNAIAjEYj3N3dERERIdaJiYmBTCZDZmZmm8u1WCwwm812hTHm+Lo1gEpLSwEAOp3ObrpOpxPnlZaWwsfHx26+QqHAwIEDxTq3Sk5OhlarFUtAQEB3NpsxJhGHGAVLSkqCyWQSS3FxsdRNYox1g24NIL1eDwAoKyuzm15WVibO0+v1KC8vt5vf1NSEiooKsc6tVCoVNBqNXWGMOb5uDaCgoCDo9Xqkp6eL08xmMzIzM2EwGAAABoMBlZWVOHr0qFgnIyMDNpsNUVFR3dkcxlhf14lBLyIiqqqqotzcXMrNzSUAtGLFCsrNzaVLly4REdF7771H7u7u9J///Ify8/PpySefpKCgIKqrqxOX8dhjj9HYsWMpMzOTDh06RMHBwTRnzpwOt4FHwbhwcYzS3ihYpwNo7969ba4oPj6eiJqH4t966y3S6XSkUqlo8uTJVFBQYLeM69ev05w5c8jV1ZU0Gg3Nnz+fqqqqOIC4cOlnpb0AEoiI4GDMZjO0Wq3UzWCMtcNkMt2xz9YhRsEYY/0TBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYkwwHEGJMMBxBjTDIcQIwxyXAAMcYk06kASk5Oxvjx4+Hm5gYfHx9Mnz4dBQUFdnXq6+uRmJgIT09PuLq6YtasWSgrK7OrU1RUhGnTpkGtVsPHxwevv/46mpqa7n5rGGOOhTohNjaWUlJS6MSJE5SXl0dTp06lwMBAqq6uFuskJCRQQEAApaenU3Z2Nk2YMIGio6PF+U1NTRQaGkoxMTGUm5tLqamp5OXlRUlJSR1uh8lkIgBcuHDp48VkMt3xWO5UAN2qvLycAND+/fuJiKiyspKcnJxo06ZNYp3Tp08TADIajURElJqaSjKZjEpLS8U6q1evJo1GQxaLpUPr5QDiwsUxSnsBdFd9QCaTCQAwcOBAAMDRo0fR2NiImJgYsc7IkSMRGBgIo9EIADAajQgLC4NOpxPrxMbGwmw24+TJk22ux2KxwGw22xXGmOPrcgDZbDYsWbIEEydORGhoKACgtLQUSqUS7u7udnV1Oh1KS0vFOjeHT8v8lnltSU5OhlarFUtAQEBXm80Y60O6HECJiYk4ceIENm7c2J3taVNSUhJMJpNYiouLe3ydjLGep+jKlxYtWoRt27bhwIED8Pf3F6fr9Xo0NDSgsrLS7iyorKwMer1erHPkyBG75bWMkrXUuZVKpYJKpepKUxljfVlnOp1tNhslJiaSn58fnT17ttX8lk7ozZs3i9POnDlDQOtO6LKyMrHOF198QRqNhurr6zvUDu6E5sLFMUq3joItWLCAtFot7du3j0pKSsRSW1sr1klISKDAwEDKyMig7OxsMhgMZDAYxPktw/CPPvoo5eXl0c6dO8nb25uH4blw6YelWwPoditJSUkR69TV1dHChQvJw8OD1Go1zZgxg0pKSuyWU1hYSHFxceTi4kJeXl60dOlSamxs5ADiwqWflfYCSPg1WByK2WyGVquVuhmMsXaYTCZoNJrbzudnwRhjkuEAYoxJhgOIMSYZDiDGmGQ4gBhjkuEAYoxJhgOIMSYZDiDGmGQ4gBhjkuEAuoVcLoe3tzfkcrnUTWGs3+MA+pVKpUJ0dDS++OILGI1GfPnll3jwwQfh7OwsddMY67fu+WfB3Nzc8PDDD+PFF1/EQw89BDc3NwiCACJCTU0NjEYjUlJSsGvXLlRUVHTLOh2RIAAzZwJaLWA0AlVVQEkJYLVK3bL26XTAjBnA1atAfj5gNgP38P/KXtXes2D3ZAAJggBvb2888cQTeO655zBu3DgolUoIgtCqLhGhqakJZ86cwTfffIPNmzejsLAQVkc48rqRTAasXQuMGgU0NgIWC3DuHHDjBnDoUPN/T5wAGhqA2lqpW2svNBT45z+b/93UBFy7Bly+3Nz+06eBS5eAK1eA+vrmbWPdhwPoJjKZDEOGDMGcOXMwd+5cBAcHQ6Ho+EshbTYbSkpK8L///Q9r165FXl4eLBZLp9vhiFoCKCSk9Tyi5gO7oqL5rOitt5r/21eEhgJr1jRvw81a/vKrq5vLrl3AqlWAzdb7beyv2gugLr2S1dE4OTkhLCwM8+fPx4wZM+Dr6wvZrX+NHSCTyTBo0CC8/PLLmDt3Lg4ePIg1a9YgPT0dlZWV3d/wPoqo+SCtrGw+cHNygOvXgZ9+ar40u+V3KPuMlsCpr29u96VLwIULwJkzzWdDZWUcPr2tXweQWq3GxIkT8cILL2DKlClwd3dv8zKrswRBgJubG+Li4jB58mScOnUKGzZswPfff4/Lly/D1k//iisq9Dh4sBQHDzZfcuXnNx/MNTVSt+zOZDI3nD5NKCioRk5O89nZhQvNl4v3yAls39Xh1xD2Ie29EdHDw4OeeeYZysjIoNraWrLZbD3aHpvNRlarlYqKiuiTTz6h8PBwcnJykvxtdN1Z5HI5xcfHS96OrpTw8HAaPXq05O24F0t7b0TsN2dALZdHTz31FObNm4eQkBAoFIpuOeNpjyAIEAQBAQEBeOWVVzBv3jzs27cPKSkp2L9/v/gDjowxew4fQHK5HCNGjEB8fDyeeuopDB48uEv9O91FEAS4u7tj+vTpiIuLQ15eHjZs2ICtW7fi6tWrIMfr82esxzh0AEVHR+Pll1/G1KlT4enp2StnO52hUqkQGRmJiIgILF26FN9//z2+/vpr/Pzzz6itreUwYvc8hw6g7777Dn5+fn0ueG4mCALkcjmCgoKwdOlSPP/88ygoKEBOTg4OHz6MY8eOobCwENXV1f2285qx23HoAGq5a9lRCIIADw8PTJgwAVFRUUhISEB1dTUuX76MY8eO4fDhw8jJycG5c+dQUVGBRr4rjvVzDh1Ajqyl41qj0SAkJAQhISF4+umnUV9fj7KyMpw6dQpZWVk4fPgwCgoKUFJSgoaGBr5sY/0KB1AfIpPJoFarERQUhCFDhmDq1KmwWq24du0azp8/j6ysLBw5cgS5ubm4evUqzGaz1E1m7K5wAPVRLZeWCoUCer0eer0e0dHRsFqtqKmpwcWLF3Hs2DEYjUbk5eXh3LlzqKqq4ss25lA4gByIIAhQKBTQarUYM2YMxowZg3nz5qG6uhrl5eXIz8+H0WjEoUOHcPbsWdy4cYM7tlmfxgHk4FoeC3Fzc8PQoUPx5JNPoqGhAZcuXUJOTg727duHw4cPo7CwEFVVVdyHxPqUTt2xt3r1ajzwwAPQaDTQaDQwGAzYsWOHOL++vh6JiYnw9PSEq6srZs2ahbJbnkwsKirCtGnToFar4ePjg9dffx1NTU3dszX3OEEQIJPJ4OzsjBEjRmDOnDlYtWoVDhw4gL1792LlypWYPXs2goODoVKpHGoEkfVPnToD8vf3x3vvvYfg4GAQEdatW4cnn3wSubm5uP/++/Hqq69i+/bt2LRpE7RaLRYtWoSZM2fixx9/BABYrVZMmzYNer0eP/30E0pKSjBv3jw4OTnhb3/7W49s4L1OLpdDq9Vi7NixGDt2LF5++WVcv34dBQUFOHjwIA4ePIj8/HyUl5dz/xHrfXf7IKaHhwd99dVXVFlZSU5OTrRp0yZx3unTpwkAGY1GIiJKTU0lmUxGpaWlYp3Vq1eTRqMhi8XS4XW2PIza3oNu7M5sNhvV19dTcXExbd++nd544w2aNGkSDRw4kBQKhd1DhfwwKpeulB57GNVqtWLTpk2oqamBwWDA0aNH0djYiJiYGLHOyJEjERgYCKPRiAkTJsBoNCIsLAw6nU6sExsbiwULFuDkyZMYO3ZsV5vDukAQBKhUKvj7+2PQoEGIi4tDXV0drl69iqysLBw4cABGoxEXLlxAXV2d1M1l/VCnA+j48eMwGAyor6+Hq6srtmzZgpCQEOTl5UGpVMLd3d2uvk6nQ2lpKQCgtLTULnxa5rfMux2LxWL35kG+/6X7tfQHqdVqDB8+HMOGDcPs2bNRW1sr3oN06dIlzJs3T+KWdp6rqyvy8/OhUCi4v7GP6XQAjRgxAnl5eTCZTNi8eTPi4+Oxf//+nmibKDk5Ge+8806ProPZa3mGzc3NTRzyd1REhIqKCvz3v//F559/jtzcXO7v6iM6/d4KpVKJ4cOHIzw8HMnJyRg9ejQ++eQT6PV6NDQ0tHo1aVlZGfR6PQBAr9e3GhVr+dxSpy1JSUkwmUxiKS4u7myz2T1MEAR4enri2Wefxe7du7Fu3TpMmjQJKpVK6qbd8+76xTk2mw0WiwXh4eFwcnJCenq6OK+goABFRUUwGAwAAIPBgOPHj6O8vFysk5aWJj4PdTsqlUoc+m8pjHWWIAjQarX43e9+h23btuGbb75BTEwM//ablDozavLmm2/S/v376eLFi5Sfn09vvvkmCYJAu3fvJiKihIQECgwMpIyMDMrOziaDwUAGg0H8flNTE4WGhtKjjz5KeXl5tHPnTvL29qakpKROjd7wKBjrDjabjWpqamj79u00bdo0UqvVko8a9bfS3jHaqQB67rnnaPDgwaRUKsnb25smT54shg8RUV1dHS1cuJA8PDxIrVbTjBkzqKSkxG4ZhYWFFBcXRy4uLuTl5UVLly6lxsbGzjSDA4h1K5vNRrW1tbRnzx6aOXMmubq6Sn7g9pfS3jHq0L8L1t5vDjHWGUSEhoYGZGdnY+XKlUhNTeX3ed+l9o5R/m14xn7Vcl9UdHQ01q1bh7S0NMyfPx+enp5SN63XqWQy9MaDOhxAjN1CEAQ4OTlh/Pjx+OKLL5CWloaEhAT4+Pj0yvrdFAo86usLZ7m8V9Z3K7VCgWeCg3HfXfz8eUdxADF2B05OThgzZgw+++wzZGRk4LXXXoOfn1+PrlPj5IQRGg3UEgWQxWpF/vXrKO2Fu9+5D4ixTrBarTh//jzWrVuHr7/+GsXFxT3yihMnQUCj4x2arbR3jHIAMdZJ1Dx6jKKiIqxfvx7ffvstiouLUdPXf6NaAhxAjPUgm80Gk8mE8+fP49ixY/jpp59w7NgxnD9/HtXV1b3+7NkAhQKzBg/G7qtX27yEEgQZBEEGmUwOudwJKqUrXFzcoVIOgIvKHXKFEgU/74HV2j2PqrR3jPIbERm7CzKZDB4eHoiIiEBERATmz5+P6upqlJSU4NixY8jKykJmZibOnz+P8vLyHg8kGQC1XA7FTS+bG+gRiEG60XBxdoeLygNaN39o1L5QOblB5eQGF6U7lApXyAQ5THXFuHw1D+aqkh5tZws+A2Ksh7RcqjU2NqKsrAxnz57F4cOHkZWVJT6S1BOXbQKa7wIEAIVchelTVmCY78NQKTQQIPxa49e6t7wVs6GpGv/96U84cea/3dIWPgNiTCItv/2mUqkQGBiIwMBATJ48GY2NjTCbzTh37hxyc3NhNBqRn5+PwsJC1NTUwGq13tV6bz6jEAQ5XFRaKOUDIBPaH1Vzkqsx1H8iTp1Nhc3W85ePHECM9SJBEKBUKuHl5QVPT09MmDABCxYsgNlsxpUrV5Cbm4vMzExkZ2fj/PnzuH79epcCqbmvp/lciGCD0IHw+fWb8PV8ABpXX1Sae/6tExxAjEnk5ssfrVYLrVaLUaNGYc6cObBYLGI/0sqVK3Ho0CG7l/K1s2QM9h8Pf9+xOPPz7k63yV0dCF+f+3slgPhGRMb6kJZfNnFxccHQoUMxffp0bN26FevWrUNUVBQUivbPGTSuejwS+WdMGJUAL89hzcvtxIMVSrkrAnzHdXkbOoMDiLE+TBAEuLq6Yvbs2dixYwdWr16NsLAwyGS3P3RHDY+FjzYEZy/vwqXiI51ep0xQwNcrDB7awRgSOAEjhk8GeujJMA4gxhyAIAjw8PDA888/j7S0NLz//vsYNmxYq1Es74HBeCB4JuobTMg8vhYNjXWw2ho6vT4XlQeC/A2Y+n/+LyaN/iMGDBjYXZtihwOIMQciCAJ0Oh2WLl2KvXv34q233oK/vz8AQC5zwvgH5sHbbSRyz32L8l8KAABNTZ0PIJmgQHFJNiqriuGtHYkRQ6egJ86COIAYc0CCICAgIABvv/029uzZg8WLF2PkiCgE6MfhF3MB8k5vApENRDZU1ZaC0Pp2v5b7lIhssJEVTbYGWJqqUNvwC+oab6CuwYSzF9JhaTJjzH1Pd+gsqOWSMTw8vEPbwaNgjDkwuVyO++67D8uXL8e5s4XI2HEFGzaugsncfCczkQ3VNeVosNZAgAAbNaLRWg9Lowk1luuwNFShzmKCqfoybpiL0NhUh7q6StwwF6O29gbOXspASPBUDBoYjvuCHkHuiU2t2iAIAnx8fBAaGoq4uDhMmTIFPj4+8PX1bbf9HECMObiWn1AaOWoYhgcPwViDEitWWLFjxw7U1NTgclkeDh7/GNU1v+CGqQgNjTVobKxHXX0lLA1V4lkQka3VsquqS/DzpQPw1o7A6OCncPZiBmpqrkOlUkGv12PixIl4/PHHERUVBT8/PyiVSgiC0OHf7uNHMRjrh+rr67F//36sWLEC+/btQ0ND5/uBWgzUBCHuN8tQYS5AZb0REydGICYmBqNHj4a3tzfkbby3qKPHKAcQY/0UEaG2tha7du3C8uXLkZWVhcbGRvEREZut9RnPzQRBwMCBAzF2zFjMmhmPcREjMWrUCAwYMEBcxu1wADHGADQHkclkwtatW/Hxxx/DdO0aBjg749SFC61epqZQKODn54fIyEhMmTIFDz/8MAICAuDs7HzHwLkVBxBjzA4R4dq1a/jff/6Df371FYxHjoCI4OLigqCgIDz44IN47LHHEBERAb1eD5lM1qnQuRkHEGOsTTabDVevXsX69etRX1+PKVOmIDQ0FBqNps3+nK7gAGKM3dHNh35Xz3Rup6PHKA/DM3aP6u7Q6Qq+E5oxJhkOIMaYZDiAGGOS4QBijEmGA4gxJhkOIMaYZBxyGL7l/oWOPnHLGOtdLcdme7cZOmQAXb9+HQAQEBAgcUsYY3dSVVUFrVZ72/kOGUADBza/ma2oqOiOG8fsmc1mBAQEoLi4mO8g7yDeZ11DRKiqqoKfn98d6zlkALX8IoBWq+U/ii7QaDS83zqJ91nndeTkgDuhGWOS4QBijEnGIQNIpVJh2bJlUKlUUjfFofB+6zzeZz3LIV/HwRjrHxzyDIgx1j9wADHGJMMBxBiTDAcQY0wyDhlAK1euxJAhQ+Ds7IyoqCgcOXJE6iZJJjk5GePHj4ebmxt8fHwwffp0FBQU2NWpr69HYmIiPD094erqilmzZqGsrMyuTlFREaZNmwa1Wg0fHx+8/vrraGpq6s1Nkcx7770HQRCwZMkScRrvs15CDmbjxo2kVCppzZo1dPLkSXrxxRfJ3d2dysrKpG6aJGJjYyklJYVOnDhBeXl5NHXqVAoMDKTq6mqxTkJCAgUEBFB6ejplZ2fThAkTKDo6Wpzf1NREoaGhFBMTQ7m5uZSamkpeXl6UlJQkxSb1qiNHjtCQIUPogQceoMWLF4vTeZ/1DocLoMjISEpMTBQ/W61W8vPzo+TkZAlb1XeUl5cTANq/fz8REVVWVpKTkxNt2rRJrHP69GkCQEajkYiIUlNTSSaTUWlpqVhn9erVpNFoyGKx9O4G9KKqqioKDg6mtLQ0euihh8QA4n3WexzqEqyhoQFHjx5FTEyMOE0mkyEmJgZGo1HClvUdJpMJwP9/YPfo0aNobGy022cjR45EYGCguM+MRiPCwsKg0+nEOrGxsTCbzTh58mQvtr53JSYmYtq0aXb7BuB91psc6mHUa9euwWq12v1PBwCdToczZ85I1Kq+w2azYcmSJZg4cSJCQ0MBAKWlpVAqlXB3d7erq9PpUFpaKtZpa5+2zOuPNm7ciJycHGRlZbWax/us9zhUALE7S0xMxIkTJ3Do0CGpm9KnFRcXY/HixUhLS4Ozs7PUzbmnOdQlmJeXF+RyeavRiLKyMuj1eola1TcsWrQI27Ztw969e+Hv7y9O1+v1aGhoQGVlpV39m/eZXq9vc5+2zOtvjh49ivLycowbNw4KhQIKhQL79+/Hp59+CoVCAZ1Ox/uslzhUACmVSoSHhyM9PV2cZrPZkJ6eDoPBIGHLpENEWLRoEbZs2YKMjAwEBQXZzQ8PD4eTk5PdPisoKEBRUZG4zwwGA44fP47y8nKxTlpaGjQaDUJCQnpnQ3rR5MmTcfz4ceTl5YklIiICc+fOFf/N+6yXSN0L3lkbN24klUpFa9eupVOnTtFLL71E7u7udqMR95IFCxaQVqulffv2UUlJiVhqa2vFOgkJCRQYGEgZGRmUnZ1NBoOBDAaDOL9lSPnRRx+lvLw82rlzJ3l7e99TQ8o3j4IR8T7rLQ4XQERE//jHPygwMJCUSiVFRkbS4cOHpW6SZAC0WVJSUsQ6dXV1tHDhQvLw8CC1Wk0zZsygkpISu+UUFhZSXFwcubi4kJeXFy1dupQaGxt7eWukc2sA8T7rHfw6DsaYZByqD4gx1r9wADHGJMMBxBiTDAcQY0wyHECMMclwADHGJMMBxBiTDAcQY0wyHECMMclwADHGJMMBxBiTDAcQY0wy/w+H9vFnkzMpiAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入gym库\n",
    "import gym\n",
    "\n",
    "# 创建LunarLanderContinuous环境，指定渲染模式为rgb_array，如果是在IDE中可以改为'human'\n",
    "env = gym.make('LunarLanderContinuous-v2', render_mode='rgb_array', continuous='False')\n",
    "# 重置环境\n",
    "env.reset()\n",
    "# 创建GymHelper\n",
    "gym_helper = GymHelper(env)\n",
    "\n",
    "# 循环N次\n",
    "for i in range(100):\n",
    "    gym_helper.render(title = str(i)) # 渲染环境\n",
    "    action = env.action_space.sample() # 从动作空间中随机选取一个动作\n",
    "    observation, reward, terminated, truncated, info = env.step(action) # 执行动作\n",
    "    if terminated or truncated: # 如果游戏结束，则结束循环\n",
    "        break\n",
    "\n",
    "# 游戏结束\n",
    "gym_helper.render(title = \"Finished\")\n",
    "# 关闭环境\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bde6585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70504874, 0.0807514 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space.sample() \n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f75653",
   "metadata": {},
   "source": [
    "### DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7d045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 演员网络（策略网络）\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, action_dim)\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.0005)  # 使用Adam优化器\n",
    "        self.apply(weight_init)  # 初始化模型权重\n",
    "\n",
    "    def forward(self, state):\n",
    "        # 前向传播过程\n",
    "        action = torch.tanh(self.fc(state))  # 输出动作，通过tanh激活函数归一化\n",
    "        return action\n",
    "\n",
    "# 评论家网络（价值网络）\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(action_dim, 256)  # 输入动作的全连接层\n",
    "        self.q = nn.Linear(256, 1)  # 输出Q值的线性层\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.0005, weight_decay=0.001)  # 使用Adam优化器，并设置权重衰减\n",
    "        self.apply(weight_init)  # 初始化模型权重\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        # 前向传播过程\n",
    "        x_s = self.fc(state)  # 状态通过第一个全连接层后接ReLU激活函数和批归一化层\n",
    "        x_a = self.fc2(action)  # 动作通过全连接层\n",
    "        x = torch.relu(x_s + x_a)  # 状态特征和动作特征相加后接ReLU激活函数\n",
    "        q = self.q(x)  \n",
    "        return q # 输出Q值\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    # 初始化模型权重的函数\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight, 1.0)\n",
    "        nn.init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041657ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经验回放缓冲区\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size, state_dim, action_dim, batch_size):\n",
    "        # 初始化回放缓冲区的大小、状态维度、动作维度和批次大小\n",
    "        self.mem_size = max_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cnt = 0\n",
    "\n",
    "        # 创建用于存储经验的数组\n",
    "        self.state_memory = np.zeros((self.mem_size, state_dim))  # 存储状态\n",
    "        self.action_memory = np.zeros((self.mem_size, action_dim))  # 存储动作\n",
    "        self.reward_memory = np.zeros((self.mem_size, ))  # 存储奖励\n",
    "        self.next_state_memory = np.zeros((self.mem_size, state_dim))  # 存储下一个状态\n",
    "        self.terminal_memory = np.zeros((self.mem_size, ), dtype=bool)  # 存储终止标志\n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        # 存储经验转换\n",
    "        mem_idx = self.mem_cnt % self.mem_size\n",
    "\n",
    "        self.state_memory[mem_idx] = state\n",
    "        self.action_memory[mem_idx] = action\n",
    "        self.reward_memory[mem_idx] = reward\n",
    "        self.next_state_memory[mem_idx] = next_state\n",
    "        self.terminal_memory[mem_idx] = done\n",
    "\n",
    "        self.mem_cnt += 1\n",
    "\n",
    "    def sample_buffer(self):\n",
    "        # 从缓冲区中随机采样一个批次的经验转换\n",
    "        mem_len = min(self.mem_size, self.mem_cnt)\n",
    "        batch = np.random.choice(mem_len, self.batch_size, replace=False)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        next_states = self.next_state_memory[batch]\n",
    "        terminals = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, next_states, terminals\n",
    "\n",
    "    def ready(self):\n",
    "        # 判断缓冲区是否已准备好进行采样\n",
    "        return self.mem_cnt >= self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9019251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DDPG:\n",
    "    def __init__(self, env, gamma=0.99, tau=0.005, action_noise=0.1, max_size=1000000, batch_size=256):\n",
    "        state_dim=env.observation_space.shape[0]\n",
    "        action_dim=env.action_space.shape[0]\n",
    "        batch_size=256\n",
    "        # 初始化DDPG算法的超参数和网络模型\n",
    "        self.gamma = gamma  # 折扣因子\n",
    "        self.tau = tau  # 软更新系数\n",
    "        self.action_noise = action_noise  # 动作噪声幅度\n",
    "        \n",
    "        # 判断可用的设备是 CPU 还是 GPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.actor = ActorNetwork(state_dim=env.observation_space.shape[0],\n",
    "                                  action_dim=env.action_space.shape[0]).to(self.device) # 创建演员网络\n",
    "        self.target_actor = ActorNetwork(state_dim=env.observation_space.shape[0],\n",
    "                                  action_dim=env.action_space.shape[0]).to(self.device) # 创建目标演员网络\n",
    "        self.critic = CriticNetwork(state_dim=env.observation_space.shape[0],\n",
    "                                  action_dim=env.action_space.shape[0]).to(self.device)  # 创建评论家网络\n",
    "        self.target_critic = CriticNetwork(state_dim=env.observation_space.shape[0],\n",
    "                                  action_dim=env.action_space.shape[0]).to(self.device)  # 创建目标评论家网络\n",
    "\n",
    "        self.memory = ReplayBuffer(max_size=max_size, state_dim=env.observation_space.shape[0],\n",
    "                                  action_dim=env.action_space.shape[0], batch_size=batch_size)  # 创建回放缓冲区\n",
    "        \n",
    "        self.update_network_parameters(tau=1.0)  # 初始化目标网络参数与主网络参数相同\n",
    "\n",
    "    def update_network_parameters(self, tau=None):\n",
    "        # 更新目标网络参数\n",
    "        if tau is None:\n",
    "            tau = self.tau\n",
    "\n",
    "        for actor_params, target_actor_params in zip(self.actor.parameters(),\n",
    "                                                     self.target_actor.parameters()):\n",
    "            target_actor_params.data.copy_(tau * actor_params + (1 - tau) * target_actor_params)\n",
    "\n",
    "        for critic_params, target_critic_params in zip(self.critic.parameters(),\n",
    "                                                       self.target_critic.parameters()):\n",
    "            target_critic_params.data.copy_(tau * critic_params + (1 - tau) * target_critic_params)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        # 存储经验转换\n",
    "        self.memory.store_transition(state, action, reward, next_state, done)\n",
    "\n",
    "    def choose_action(self, observation, train=True):\n",
    "        # 根据当前状态选择动作\n",
    "        self.actor.eval()\n",
    "        state = torch.FloatTensor(observation).to(self.device)\n",
    "        action = self.actor.forward(state).squeeze()\n",
    "\n",
    "        if train:\n",
    "            noise = torch.tensor(np.random.normal(loc=0.0, scale=self.action_noise),\n",
    "                             dtype=torch.float).to(self.device)\n",
    "            action = torch.clamp(action + noise, -1, 1)\n",
    "            return action.cpu().detach().numpy()\n",
    "        self.actor.train()\n",
    "        return action.cpu().detach().numpy()\n",
    "\n",
    "    def learn(self):\n",
    "        # 使用经验回放进行训练\n",
    "        if not self.memory.ready():\n",
    "            return\n",
    "        \n",
    "        # 从回放缓冲区中获取一批样本\n",
    "        states, actions, rewards, next_states, dones = self.memory.sample_buffer()\n",
    "        states = torch.FloatTensor(np.array(states)).to(self.device)\n",
    "        actions = torch.FloatTensor(np.array(actions)).to(self.device)\n",
    "        rewards = torch.FloatTensor(np.array(rewards)).to(self.device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(self.device)\n",
    "        dones = torch.LongTensor(np.array(dones)).to(self.device)\n",
    "        \n",
    "        # 使用目标演员网络生成下一个状态对应的下一个动作，并计算目标评论家网络对应的 Q 值。\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.target_actor.forward(next_states)\n",
    "            q_ = self.target_critic.forward(next_states, next_actions).view(-1)\n",
    "            q_[dones] = 0.0\n",
    "            target = rewards + self.gamma * q_\n",
    "        \n",
    "        # 使用当前评论家网络计算当前状态和动作对应的 Q 值\n",
    "        q = self.critic.forward(states, actions).view(-1)\n",
    "\n",
    "        # 计算评论家网络的损失，并根据损失进行反向传播和优化\n",
    "        critic_loss = F.mse_loss(q, target)\n",
    "        \n",
    "        self.critic.optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic.optimizer.step()\n",
    "        \n",
    "        # 生成当前状态对应的新动作，并计算演员网络的损失\n",
    "        new_actions = self.actor.forward(states)\n",
    "        actor_loss = -torch.mean(self.critic(states, new_actions))\n",
    "        \n",
    "        # 根据演员网络的损失进行反向传播和优化\n",
    "        self.actor.optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor.optimizer.step()\n",
    "        \n",
    "        # 更新目标网络的参数。\n",
    "        self.update_network_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e1d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: -896.3220589740599                                                                                          \n",
      "  0%|▏                                                                                | 3/1500 [00:00<02:31,  9.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\74760\\AppData\\Local\\Temp\\ipykernel_37664\\3270783388.py:73: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  dones = torch.LongTensor(np.array(dones)).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40: -430.2609921038793                                                                                         \n",
      "Episode 80: -538.441952068596                                                                                          \n",
      "Episode 120: -581.2011617436613                                                                                        \n",
      "Episode 160: -227.64773620862582                                                                                       \n",
      "Episode 200: -216.7406032311452                                                                                        \n",
      "Episode 240: -82.59713520968424                                                                                        \n",
      "Episode 280: -87.67055723396129                                                                                        \n",
      "Episode 320: -108.832376328824                                                                                         \n",
      "Episode 360: -85.90654939000514                                                                                        \n",
      "Episode 400: -121.35331636446666                                                                                       \n",
      "Episode 440: -43.262466689422396                                                                                       \n",
      "Episode 480: -12.841797169428075                                                                                       \n",
      "Episode 520: -56.93162975400997                                                                                        \n",
      "Episode 560: -15.757794625331492                                                                                       \n",
      " 38%|████████████████████████████▏                                              | 563/1500 [2:09:40<9:48:47, 37.70s/it]"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "from tqdm import * # 用于显示进度条\n",
    "\n",
    "# 定义超参数\n",
    "max_episodes = 1500 # 训练episode数\n",
    "max_steps = 1000 # 每个回合的最大步数\n",
    "\n",
    "# 创建DDPG对象\n",
    "agent = DDPG(env)\n",
    "# 定义保存每个回合奖励的列表\n",
    "episode_rewards = []\n",
    "\n",
    "# 开始循环，tqdm用于显示进度条并评估任务时间开销\n",
    "for episode in tqdm(range(max_episodes), file=sys.stdout):\n",
    "    # 重置环境并获取初始状态\n",
    "    state, _ = env.reset()\n",
    "    # 当前回合的奖励\n",
    "    episode_reward = 0\n",
    "\n",
    "    # 循环进行每一步操作\n",
    "    for step in range(max_steps):\n",
    "        # 根据当前状态选择动作\n",
    "        action = agent.choose_action(state)\n",
    "        \n",
    "        # 执行动作，获取新的信息\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # 将五元组加到经验回放缓冲区\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        agent.learn()\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # 更新当前状态\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    # 记录当前回合奖励值\n",
    "    episode_rewards.append(episode_reward)\n",
    "\n",
    "    # 打印中间值\n",
    "    if episode % 40 == 0:\n",
    "        tqdm.write(\"Episode \" + str(episode) + \": \" + str(episode_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Matplotlib绘制奖励值的曲线图\n",
    "plt.plot(episode_rewards)\n",
    "plt.title(\"reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa8efb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 重置环境，开始新的一轮游戏\n",
    "observation, _ = env.reset()\n",
    "# 创建GymHelper对象来辅助显示\n",
    "gym_helper = GymHelper(env)\n",
    "\n",
    "# 开始游戏\n",
    "for i in range(500):\n",
    "    # 渲染环境，title为当前步骤数\n",
    "    gym_helper.render(title = str(i))\n",
    "    \n",
    "    # 找到当前状态下的最优动作\n",
    "    action = agent.choose_action(observation)\n",
    "    \n",
    "    # 执行action，获取新的信息\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # 如果游戏结束，则结束当前循环\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "# 游戏结束\n",
    "gym_helper.render(title = \"Finished\")\n",
    "# 关闭环境\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c6d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
